<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4001/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4001/" rel="alternate" type="text/html" /><updated>2021-03-10T01:05:58-05:00</updated><id>http://localhost:4001/feed.xml</id><title type="html">Your awesome title</title><subtitle>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.</subtitle><entry><title type="html">Object Detection YOLOv3 Mindmap</title><link href="http://localhost:4001/jekyll/update/projects/2021/02/25/YOLO-Mindmap.html" rel="alternate" type="text/html" title="Object Detection YOLOv3 Mindmap" /><published>2021-02-25T15:13:14-05:00</published><updated>2021-02-25T15:13:14-05:00</updated><id>http://localhost:4001/jekyll/update/projects/2021/02/25/YOLO-Mindmap</id><content type="html" xml:base="http://localhost:4001/jekyll/update/projects/2021/02/25/YOLO-Mindmap.html">&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;a href=&quot;http://localhost:4001/assets/2021-02-25-YOLO-Mindmap/YOLO.jpg&quot;&gt;
   &lt;img src=&quot;http://localhost:4001/assets/2021-02-25-YOLO-Mindmap/YOLO.jpg&quot; alt=&quot;drawing&quot; style=&quot;width: 100%;&quot; /&gt;
    &lt;/a&gt;
   &lt;figcaption&gt;YOLO project resource overview&lt;/figcaption&gt;
&lt;/div&gt;</content><author><name>Zizhun Guo</name></author><category term="Projects" /><summary type="html">YOLO project resource overview</summary></entry><entry><title type="html">Certificate/Courses: DeepLearning.AI Deep Learning Specialization Mindmap/Notes/Certificate</title><link href="http://localhost:4001/jekyll/update/projects/2021/01/07/Deep-Learning-Specialization.html" rel="alternate" type="text/html" title="Certificate/Courses: DeepLearning.AI Deep Learning Specialization Mindmap/Notes/Certificate" /><published>2021-01-07T15:13:14-05:00</published><updated>2021-01-07T15:13:14-05:00</updated><id>http://localhost:4001/jekyll/update/projects/2021/01/07/Deep-Learning-Specialization</id><content type="html" xml:base="http://localhost:4001/jekyll/update/projects/2021/01/07/Deep-Learning-Specialization.html">&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;a href=&quot;http://localhost:4001/assets/2021-01-07-Deep-Learning-Specialization/DL_coursera.jpg&quot;&gt;
   &lt;img src=&quot;http://localhost:4001/assets/2021-01-07-Deep-Learning-Specialization/DL_coursera.jpg&quot; alt=&quot;drawing&quot; style=&quot;width: 70%;&quot; /&gt;
    &lt;/a&gt;
   &lt;figcaption&gt;Deep Learning Specialization Notes&lt;/figcaption&gt;
&lt;/div&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;a href=&quot;https://www.coursera.org/account/accomplishments/specialization/XZQ953AVUJUT&quot;&gt;
   &lt;img src=&quot;http://localhost:4001/assets/2021-01-07-Deep-Learning-Specialization/certificate.png&quot; alt=&quot;drawing&quot; style=&quot;width: 100%;&quot; /&gt;
    &lt;/a&gt;
   &lt;figcaption&gt;&lt;a href=&quot;https://www.coursera.org/account/accomplishments/specialization/XZQ953AVUJUT&quot;&gt;Certificate Link: https://www.coursera.org/account/accomplishments/specialization/XZQ953AVUJUT&lt;/a&gt;&lt;/figcaption&gt;
&lt;/div&gt;

&lt;h3 id=&quot;resources&quot;&gt;Resources&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/fengdu78/deeplearning_ai_books&quot;&gt;Course Notes CN&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/mbadry1/DeepLearning.ai-Summary&quot;&gt;Course Notes EN&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://baozoulin.gitbook.io/neural-networks-and-deep-learning/di-er-men-ke-gai-shan-shen-ceng-shen-jing-wang-luo-chao-can-shu-tiao-shi-zheng-ze-hua-yi-ji-you-hua/improving-deep-neural-networks/practical-aspects-of-deep-learning/14-zheng-ze-hua-ff08-regularization&quot;&gt;Course Summary CN&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Zizhun Guo</name></author><category term="Projects" /><summary type="html">Deep Learning Specialization Notes</summary></entry><entry><title type="html">Certificate/Courses: TensorFlow Developer Certificate</title><link href="http://localhost:4001/jekyll/update/projects/2021/01/07/TensorFlow-Developer-Certificate-copy.html" rel="alternate" type="text/html" title="Certificate/Courses: TensorFlow Developer Certificate" /><published>2021-01-07T15:13:14-05:00</published><updated>2021-01-07T15:13:14-05:00</updated><id>http://localhost:4001/jekyll/update/projects/2021/01/07/TensorFlow-Developer-Certificate%20copy</id><content type="html" xml:base="http://localhost:4001/jekyll/update/projects/2021/01/07/TensorFlow-Developer-Certificate-copy.html">&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;a href=&quot;http://localhost:4001/assets/2021-01-31-TensorFlow-Developer-Certificate/TensorFlow_Certificate.jpg&quot;&gt;
   &lt;img src=&quot;http://localhost:4001/assets/2021-01-31-TensorFlow-Developer-Certificate/TensorFlow_Certificate.jpg&quot; alt=&quot;drawing&quot; style=&quot;width: 70%;&quot; /&gt;
    &lt;/a&gt;
   &lt;figcaption&gt;TensorFlow Developer Certificate Notes in Details&lt;/figcaption&gt;
&lt;/div&gt;

&lt;h3 id=&quot;reference-courses-for-preparation&quot;&gt;Reference Courses for preparation:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.coursera.org/professional-certificates/tensorflow-in-practice?utm_source=gg&amp;amp;utm_medium=sem&amp;amp;utm_campaign=33-DeepLearningAI-TensorFlow-US&amp;amp;utm_content=33-DeepLearningAI-TensorFlow-US&amp;amp;campaignid=12447638588&amp;amp;adgroupid=120038996082&amp;amp;device=c&amp;amp;keyword=tensorflow%20developer&amp;amp;matchtype=p&amp;amp;network=g&amp;amp;devicemodel=&amp;amp;adpostion=&amp;amp;creativeid=501889850765&amp;amp;hide_mobile_promo&amp;amp;gclid=Cj0KCQiA1pyCBhCtARIsAHaY_5cDU3bKFC0azYWxzLnTFIZbYzlxpwXN0-W4ci2PlqnRIxTcVf247iIaAmPYEALw_wcB&quot;&gt;Coursera(semi-Official)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/lmoroney/dlaicourse&quot;&gt;Coursera(semi-Official) - Github&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://classroom.udacity.com/courses/ud187&quot;&gt;Udacity(Official)- Intro to TensorFlow for Deep Learning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;a href=&quot;https://www.coursera.org/account/accomplishments/specialization/XZQ953AVUJUT&quot;&gt;
   &lt;img src=&quot;http://localhost:4001/assets/2021-01-31-TensorFlow-Developer-Certificate/certificate.png&quot; alt=&quot;drawing&quot; style=&quot;width: 100%;&quot; /&gt;
    &lt;/a&gt;
   &lt;figcaption&gt;&lt;a href=&quot;https://www.credential.net/2f7e7dc7-237d-4fbc-b8af-0d40c82155e8#gs.v5yedg&quot;&gt;Certificate Link: https://www.credential.net/2f7e7dc7-237d-4fbc-b8af-0d40c82155e8#gs.v5yedg&lt;/a&gt;&lt;/figcaption&gt;
&lt;/div&gt;</content><author><name>Zizhun Guo</name></author><category term="Projects" /><summary type="html">TensorFlow Developer Certificate Notes in Details</summary></entry><entry><title type="html">(8/8)NN Models - Text Mining for Multiclass Classification based on Yelp User’s Reviews</title><link href="http://localhost:4001/jekyll/update/projects/2020/12/15/Text-Mining-NN_Models.html" rel="alternate" type="text/html" title="(8/8)NN Models - Text Mining for Multiclass Classification based on Yelp User’s Reviews" /><published>2020-12-15T13:50:07-05:00</published><updated>2020-12-15T13:50:07-05:00</updated><id>http://localhost:4001/jekyll/update/projects/2020/12/15/Text-Mining-NN_Models</id><content type="html" xml:base="http://localhost:4001/jekyll/update/projects/2020/12/15/Text-Mining-NN_Models.html">&lt;h3 id=&quot;neural-network-models&quot;&gt;Neural Network Models&lt;/h3&gt;
&lt;hr /&gt;

&lt;h3 id=&quot;python-files&quot;&gt;Python Files&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;create_CNN_model.py&lt;/strong&gt;: This files contains the python code to create the CNN model used for the experiments.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;create_RNN_model.py&lt;/strong&gt;: This files contains the python code to create the RNN model used for the experiments.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;tuning_CNN_model.py&lt;/strong&gt;: This files contains the python code for tuning the CNN model used for the experiments.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;1-tensorflow-keras-embedding-layer&quot;&gt;1. Tensorflow Keras Embedding Layer&lt;/h3&gt;

&lt;p&gt;The embedding layer is a special layer that is normally placed at the beginning of a neural network. Similar to W2V, it is an individual layer trained to work as a lookup table for the one-hot encoding input documents. The weights matrix represents the word embeddings. The documents which are made of the list of sequence would be converted into a stack of word vectors. We employ the average pooling layer to produce the mean word embeddings to represent a single document for normal W2V cases, but in our CNN model or RNN models, we would use more strategies to use the embedding layer’s output. Besides, the weights matrix of the embedding layer would be trained along with the other parameters of the neural network using the back-propagation method.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4001/assets/2020-12-15-Text-Mining/images/NN_models/Embedding_layer_model.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 1: Textual Model Structure using TensorFlow Keras Embedding Layer&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;2-cnn&quot;&gt;2. CNN&lt;/h3&gt;
&lt;p&gt;As one of famous deep learning models, CNN has been widely used in computer vision tasks. Since the year of 2014, the CNN has been discovered to be proved successfully workable not only the computer vision jobs but also the text classification.&lt;/p&gt;

&lt;h5 id=&quot;21-model-architecture&quot;&gt;2.1. Model Architecture&lt;/h5&gt;

&lt;p&gt;In our experiment, we implement a CNN model with its architecture designed based on the Yoon Kim’s architecture. The Embedding Layer works for training the word embeddings as it was been discussed previously. The Convolutional Layer has hundreds of feature maps as filters to convolute the document representation. The Global Max Layer is charged for keeping the most unique value to represent an independent document among all. The Dropout layer works as a regularization role. At last, the Softmax layer computes the probability distribution for three categories. We then classify the sample into the category which has the greatest value. In our experiments, we use the TensorFlow Keras deep learning library to implement this CovNet.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4001/assets/2020-12-15-Text-Mining/images/NN_models/CNN_architecture.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 2: CNN model architecture&lt;/strong&gt;&lt;/p&gt;

&lt;h5 id=&quot;22-hyperparameters-tuning&quot;&gt;2.2. Hyperparameters Tuning&lt;/h5&gt;
&lt;p&gt;In order to find the CNN model that produces the highest prediction accuracy, we have tuned the model regarding three hyperparameters that are hugely affected the model’s performance: Sequence Size, Filter Region Size and Feature Maps numbers.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tuning Sequence Size:&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Sequence Size&lt;/th&gt;
      &lt;th&gt;Val_Acc&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;0.722&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;20&lt;/td&gt;
      &lt;td&gt;0.7905&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;30&lt;/td&gt;
      &lt;td&gt;0.835167&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;50&lt;/td&gt;
      &lt;td&gt;0.874&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;100&lt;/td&gt;
      &lt;td&gt;0.906667&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;200&lt;/td&gt;
      &lt;td&gt;0.926667&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;400&lt;/td&gt;
      &lt;td&gt;0.938167&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;800&lt;/td&gt;
      &lt;td&gt;0.944&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1000&lt;/td&gt;
      &lt;td&gt;0.9475&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4001/assets/2020-12-15-Text-Mining/images/NN_models/acc_sequence_sizes_forReport.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 3: CNN model train/validate Accuracy vs Embedding Sequence Sizes&lt;/strong&gt;
&lt;strong&gt;Tuning Filter Region Size:&lt;/strong&gt;
| Sequence Size   | Val_Acc |
| ———– | ———– |
|1	|0.946667|
|3	|0.947833|
|5	|0.945833|
|7	|0.944333|
|10	|0.941833|
|15	|0.942|
|20	|0.938833|
|25	|0.937333|
|30	|0.9385|&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4001/assets/2020-12-15-Text-Mining/images/NN_models/acc_filter_region_sizes_forReport.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 4: CNN model train/validate Accuracy vs Embedding Filter Region Sizes&lt;/strong&gt;
&lt;strong&gt;Tuning Embedding Trainable Methods:&lt;/strong&gt;
| Trainable  | Val_Acc |
| ———– | ———– |
|non-static	|0.948667|
|static	|0.9475|&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tuning Filter Feature Maps Numbers:&lt;/strong&gt;
|Feature Maps Numbers|Val_Acc|
| ———– | ———– |
|10|	0.925167|
|20|	0.936|
|30|	0.937667|
|50|	0.943167|
|100|	0.947167|
|200|	0.948667|
|400|	0.948833|
|800|	0.951667|
|1000|	0.951833|
&lt;img src=&quot;http://localhost:4001/assets/2020-12-15-Text-Mining/images/NN_models/acc_filter_featuremaps_numbers_forReport.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 5: CNN model train/validate Accuracy vs Featuremaps Number&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Configuration&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Input word vectors:	GloVe 300d&lt;/li&gt;
  &lt;li&gt;Static or non-static:	static&lt;/li&gt;
  &lt;li&gt;Filter region size (window):	3&lt;/li&gt;
  &lt;li&gt;Stride:	1&lt;/li&gt;
  &lt;li&gt;Feature maps:	1000&lt;/li&gt;
  &lt;li&gt;Activation function:	ReLU&lt;/li&gt;
  &lt;li&gt;Pooling: 	GlobalMaxPooling&lt;/li&gt;
  &lt;li&gt;Dropout rate:	0.5&lt;/li&gt;
  &lt;li&gt;Optimizer:	Adam&lt;/li&gt;
  &lt;li&gt;Batch size:	128&lt;/li&gt;
  &lt;li&gt;Epochs:	20&lt;/li&gt;
  &lt;li&gt;Cross Validation:	10-folds&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-rnn-model-architecture&quot;&gt;3. RNN Model Architecture&lt;/h3&gt;
&lt;h5 id=&quot;31-encoder-architecture&quot;&gt;3.1. Encoder Architecture&lt;/h5&gt;
&lt;p&gt;Recurrent Neural Network (RNN) has long been used for learning the sequence of documents employing a directed node graph along temporal steps. We adopt the Encoder part of the RNN-Encoder-Decoder model as our RNN architecture since the architecture fits the requirement of the text classification task that documents can be input along with the temporal steps and in the end, the memory unit will produce a document representation. As seen from the figure 5, the encoder takes in a variable-length sequence 〖(X〗_1,X_2,…,X_T)and converts it into a fixed-length vector representation C. 
&lt;img src=&quot;http://localhost:4001/assets/2020-12-15-Text-Mining/images/NN_models/RNN-Encoder.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 6: RNN Encoder Model&lt;/strong&gt;&lt;/p&gt;

&lt;h5 id=&quot;32-gru-and-lstm&quot;&gt;3.2. GRU and LSTM&lt;/h5&gt;
&lt;p&gt;LSTM has a longer history than GRU. It was firstly introduced in 1997 and was modified throughout the time. New features like forget gate and peephole would add during the evolution. The GRU is a newer generation of RNN work similar to LSTM that enables memorizing the short-term and long-term dependencies by implementing a reset gate and an update gate during training. There is no memory cell as it is called in LSTM but has a hidden state works the same function. The figure 6 shows the inner structure of two memory units.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4001/assets/2020-12-15-Text-Mining/images/NN_models/GRU_LSTM.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 7: Unit Comparison between naïve RNN, LSTM and GRU&lt;/strong&gt;&lt;/p&gt;

&lt;h5 id=&quot;33-model-architecture&quot;&gt;3.3. Model Architecture&lt;/h5&gt;
&lt;p&gt;In our experiment, we implement a RNN decoder model with its architecture designed based on the Cho’s architecture. It works the same way as it was described in the CNN model’s section. The document-representation sends the batches of samples in the Input Layer at the beginning. After the embedding process by the Embedding Layer, the embeddings are continuously transferred to GRU layer. Through a recurrent time-based learning process using the Backpropagation method, the weights of the model would be updated. The final layer is the Softmax Layer which works to classify the samples into three categories.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4001/assets/2020-12-15-Text-Mining/images/NN_models/RNN_GRU.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 8: RNN-GRU model architecture&lt;/strong&gt;
As for memory unit, the Encoder model can use either Gated Recurrent Unit (GRU) or Long-short term Memory (LSTM) to memorize the historical dependencies as in the form of the hidden state.&lt;/p&gt;

&lt;h3 id=&quot;appendix&quot;&gt;Appendix&lt;/h3&gt;

&lt;h5 id=&quot;a1-other-layers-details&quot;&gt;A1. Other layers details&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;Global Max Pooling Layer&lt;/strong&gt;
The output tensors from convolution layer yields concatenate results of each 128 filters’ hence the original matrix turns into the vector. For each sequence, we only keep the maximum value which maintains the review local feature.
&lt;strong&gt;Concatenate Layer and Flatten Layer&lt;/strong&gt;
We concatenate all results of three types of filters and flatten readily for the neurons to take.
&lt;strong&gt;Regularization: Dropout Layer&lt;/strong&gt;
We assign a Dropout Layer as regularization masks to help prevent overfitting issue.
&lt;strong&gt;Fully Connected Layer&lt;/strong&gt;
We only assign a dense layer as the output layer using activation function of Softmax.&lt;/p&gt;

&lt;h5 id=&quot;a2-tensorflow-keras-summary&quot;&gt;A2. TensorFlow Keras Summary&lt;/h5&gt;
&lt;p&gt;•	Utils.plot_model: Plot Model diagram. It requires pydot and graphviz, which should be installed to python lib and set executable directory into system environment path.
•	Optimizers: Provides different classes of optimize rule like ‘Adam’, ‘Adadelta’, etc.
•	Layers: All types of NN layers like ‘Flatten’, ‘Concatenate’, etc
•	Experimental.preprocessing.TextVectorization&lt;/p&gt;

&lt;h5 id=&quot;a3-gpu-acceleration&quot;&gt;A3. GPU Acceleration&lt;/h5&gt;
&lt;p&gt;NVIDIA GPU with CUDA architectures supports acceleration for TensorFlow, therefore by using GPU to process DL tasks is good. Currently, my machine has a video card of GeForce GTX 1060 6GB, which has the compute Capability of 6.1. They way to implement it is to install CUDA and NVCC on the machine. The TF will automatically search out the installation and use it while training. After getting deeper knowledge about TF, specific operation controlling GPU/CPU as multiple purpose can be achieve by coding without Keras package instead the self-configure TF package.&lt;/p&gt;

&lt;h3 id=&quot;resources&quot;&gt;Resources&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Implementing a CNN for Text Classification in TensorFlow: http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/&lt;/li&gt;
  &lt;li&gt;Understanding Convolutional Neural Networks for NLP: http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/&lt;/li&gt;
  &lt;li&gt;Global Max Pooling vs Max Pooling: https://stackoverflow.com/questions/43728235/what-is-the-difference-between-keras-maxpooling1d-and-globalmaxpooling1d-functi/43730861
Multi Class Text Classification with Keras and LSTM: https://medium.com/@djajafer/multi-class-text-classification-with-keras-and-lstm-4c5525bef592
Report on Text Classification using CNN, RNN &amp;amp; HAN: https://medium.com/jatana/report-on-text-classification-using-cnn-rnn-han-f0e887214d5f
Text classification with an RNN: https://www.tensorflow.org/tutorials/text/text_classification_rnn&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Zizhun Guo</name></author><category term="Projects" /><summary type="html">Neural Network Models</summary></entry><entry><title type="html">(7/8)ML Models - Text Mining for Multiclass Classification based on Yelp User’s Reviews</title><link href="http://localhost:4001/jekyll/update/projects/2020/12/15/Text-Mining-ML-Models.html" rel="alternate" type="text/html" title="(7/8)ML Models - Text Mining for Multiclass Classification based on Yelp User’s Reviews" /><published>2020-12-15T13:50:06-05:00</published><updated>2020-12-15T13:50:06-05:00</updated><id>http://localhost:4001/jekyll/update/projects/2020/12/15/Text-Mining-ML-Models</id><content type="html" xml:base="http://localhost:4001/jekyll/update/projects/2020/12/15/Text-Mining-ML-Models.html">&lt;h3 id=&quot;ml-models&quot;&gt;ML Models&lt;/h3&gt;
&lt;hr /&gt;
&lt;h3 id=&quot;python-files&quot;&gt;Python Files&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;tuning_ML_models.py&lt;/strong&gt;: This files contains the python code to tune the ML models.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;1-perceptron-model&quot;&gt;1. Perceptron Model&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;11-purpose&quot;&gt;1.1. Purpose&lt;/h4&gt;
    &lt;ul&gt;
      &lt;li&gt;Tune the model by iterating values of two hyperparameters to compare results and analyze how it works with the aids of mathematical formulas&lt;/li&gt;
      &lt;li&gt;Understand L1/L2 norm and how it affects the loss function&lt;/li&gt;
      &lt;li&gt;Revise gradient descent and learn perceptron with back-propagation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;12-hyperparameters&quot;&gt;1.2. Hyperparameters&lt;/h4&gt;
    &lt;ul&gt;
      &lt;li&gt;Stepping Criteria: tol&lt;/li&gt;
      &lt;li&gt;Regularization Constant: alpha&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;13-principle&quot;&gt;1.3. Principle:&lt;/h4&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Stopping Criteria ‘tol’&lt;/strong&gt;
  The perceptron learning model adopts SGD to fit itself. The way to compute the gradients is through back-propagation. It implements the chain rule to update the weights of the perceptron model, as it is the same for many other neural network structures. Stopping criteria as one essential hyper-parameter of the model control when to stop for the training process. Together with max_iteration times (which defines the ending condition), it somehow affects the model performance.
        &lt;blockquote&gt;
          &lt;h5 id=&quot;loss--errory-y-1&quot;&gt;$Loss = Error(y, y’)$ (1)&lt;/h5&gt;
          &lt;h5 id=&quot;loss--previousloss---tol--2&quot;&gt;$Loss &amp;gt; previousLoss - tol$  (2)&lt;/h5&gt;
          &lt;h5 id=&quot;y---y--y---y---tol-3&quot;&gt;$y’ - y &amp;gt; y’’ - y - tol$ (3)&lt;/h5&gt;
          &lt;p&gt;(1) and (2) are the definition of Loss function and how it is implemented for the stopping criteria. From (1) and (2), we get (3) that once the difference between two loss gets less than ‘tol’, in other words, the changing rate of loss becomes acceptable, the training process would stop as the model is considered convergent.&lt;/p&gt;
        &lt;/blockquote&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Alpha&lt;/strong&gt;
  Alpha is a regularization rate that determines how much the l1/l2 norm(in our case) affects the loss function. If it is high, the greater proportion the regularization takes, so loss functions tend to prone to smaller weights, therefore as it gets convergent, the model is less overfitted, since the smaller weights decide less change once the predict on samples.
        &lt;blockquote&gt;
          &lt;p&gt;$L_1 = L + \alpha |W|$ (4)
$L_2 = L + \alpha W^2$ (5)
$W’ = W - \alpha \Delta (6)$&lt;/p&gt;
        &lt;/blockquote&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;(4) and (5) are the formula that describe the Loss function aided by the regularization. (6) shows that each iteration of the gradient decent, the weights decreases more. Therefore as the model converges, the weights are smaller than what the regularization is not included.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;14-results-and-analysis&quot;&gt;1.4. Results and Analysis&lt;/h4&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;‘tol’&lt;/strong&gt;
        &lt;ul&gt;
          &lt;li&gt;When the ‘tol’ is in the range between $1/10^1$ to $1/10^2$, the f1 is irregularly chaotic, this may own to the high ‘tol’ value that terminates the iteration process sooner than it is supposed to be converged.&lt;/li&gt;
          &lt;li&gt;In contrast, once ‘tol’ gets smaller enough (in the range between $1/10^3$ to $1/10^4$), the f1 socre is more stable. 
  &lt;img src=&quot;http://localhost:4001/assets/2020-12-15-Text-Mining/images/ML_models/perceptron_tol.png&quot; alt=&quot;Paris&quot; class=&quot;center&quot; /&gt;&lt;/li&gt;
        &lt;/ul&gt;
        &lt;div align=&quot;center&quot;&gt;Figure 1: F1 score of Perceptron model vs Stopping Criteria&lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;‘alpha’&lt;/strong&gt;
        &lt;ul&gt;
          &lt;li&gt;Overall trend: f1 scores increases in sigmoid-like shape, of which the alpha value is high (left-hand side) and small on the right-hand side.&lt;/li&gt;
          &lt;li&gt;When the alpha value is high, the regularization affects more in loss function, the optimal weights produced from training serves lower performance due to the penalty from the regularization.&lt;/li&gt;
          &lt;li&gt;When the alpha value is low, the model tends to be overfitted since the weights of the perceptron model get greater.&lt;/li&gt;
          &lt;li&gt;Comparing L1 norm and L2 norm, once the perceptron model arrives convergence (alpha equals around $1/10^3$), the L2 model is slightly less performed than L1 model. This can be seen as a result of the compromise that with the same alpha value assigned, L2 norm prone to produce lower weights(weight decay) hence sacrifice some precision and recall.
&lt;img src=&quot;http://localhost:4001/assets/2020-12-15-Text-Mining/images/ML_models/perceptron_alpha.png&quot; alt=&quot;Paris&quot; class=&quot;center&quot; /&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;div align=&quot;center&quot;&gt;Figure 1: F1 score of Perceptron model vs Stopping Criteria&lt;/div&gt;

&lt;h3 id=&quot;2-other-ml-models-lrsvm&quot;&gt;2. Other ML models: LR/SVM&lt;/h3&gt;
&lt;p&gt;Please check out textual models &lt;a href=&quot;../textuals_models/README.md&quot;&gt;README.md&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;resources&quot;&gt;Resources&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://towardsdatascience.com/intuitions-on-l1-and-l2-regularisation-235f2db4c261#1d17&quot;&gt;Intuitions on L1 and L2 Regularisation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://towardsdatascience.com/weight-decay-l2-regularization-90a9e17713cd&quot;&gt;Weight Decay == L2 Regularization?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://towardsdatascience.com/regularization-in-deep-learning-l1-l2-and-dropout-377e75acc036&quot;&gt;Regularization in Deep Learning — L1, L2, and Dropout&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.kdnuggets.com/2019/12/5-techniques-prevent-overfitting-neural-networks.html#:~:text=One%20of%20the%20most%20common,data%20that%20is%20too%20noisy.&amp;amp;text=The%20goal%20of%20a%20machine,data%20from%20the%20problem%20domain.&quot;&gt;5 Techniques to Prevent Overfitting in Neural Networks&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://stackoverflow.com/questions/37953585/what-is-the-difference-between-sgd-and-back-propagation&quot;&gt;What is the difference between SGD and back-propagation?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Zizhun Guo</name></author><category term="Projects" /><summary type="html">ML Models Python Files tuning_ML_models.py: This files contains the python code to tune the ML models.</summary></entry><entry><title type="html">(6/8)Experiment - Text Mining for Multiclass Classification based on Yelp User’s Reviews</title><link href="http://localhost:4001/jekyll/update/projects/2020/12/15/Text-Mining-Experiment.html" rel="alternate" type="text/html" title="(6/8)Experiment - Text Mining for Multiclass Classification based on Yelp User’s Reviews" /><published>2020-12-15T13:50:05-05:00</published><updated>2020-12-15T13:50:05-05:00</updated><id>http://localhost:4001/jekyll/update/projects/2020/12/15/Text-Mining-Experiment</id><content type="html" xml:base="http://localhost:4001/jekyll/update/projects/2020/12/15/Text-Mining-Experiment.html">&lt;h3 id=&quot;experiment&quot;&gt;Experiment&lt;/h3&gt;
&lt;hr /&gt;

&lt;h3 id=&quot;python-files&quot;&gt;Python Files&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;run_ML.py&lt;/strong&gt;: This files contains the python code to run traditional ML models.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;run_RNN.py&lt;/strong&gt;: This files contains the python code to run the RNN model.
    &lt;h3 id=&quot;library&quot;&gt;Library&lt;/h3&gt;
  &lt;/li&gt;
  &lt;li&gt;TensorFlow Keras
    &lt;h3 id=&quot;rnn-model&quot;&gt;RNN model&lt;/h3&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;rnn-gru-architecture&quot;&gt;RNN-GRU architecture&lt;/h5&gt;
&lt;p&gt;&lt;img src=&quot;../images/experiment/rnn_gru_model.png&quot; alt=&quot;&quot; /&gt;
Figure 1: RNN-GRU&lt;/p&gt;

&lt;h5 id=&quot;rnn-bidirectional-lstm-architecture&quot;&gt;RNN-Bidirectional LSTM architecture&lt;/h5&gt;
&lt;p&gt;&lt;img src=&quot;../images/experiment/rnn_model_BiLSTM.png&quot; alt=&quot;&quot; /&gt;
Figure 2: RNN-BiLSTM&lt;/p&gt;

&lt;h5 id=&quot;some-important-details&quot;&gt;Some important details:&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;Single Layered RNN-GRU and Bidirectional RNN-LSTM is are the two models that would eventually converge to produce a decent accuracy. However, the other two models – Multi-layered RNN-GRU and Single layered LSTM cannot converge.&lt;/li&gt;
  &lt;li&gt;The training/testing observation showed that if the loss for each iteration becomes below 1.0, the model would be quickly converged in the next 2-3 epochs.&lt;/li&gt;
  &lt;li&gt;The single layered RNN-GRU is the encoder model of RNN-Encoder Decoder.&lt;/li&gt;
  &lt;li&gt;Word Embedding dimensions: 300&lt;/li&gt;
  &lt;li&gt;Hidden States dimensions: 64, 128 (bidirectional RNN-LSTM)&lt;/li&gt;
  &lt;li&gt;Max sequence length: 1000 (padded with 0)&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;results&quot;&gt;Results&lt;/h5&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Models&lt;/th&gt;
      &lt;th&gt;Training&lt;/th&gt;
      &lt;th&gt;Testing&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Single Layered RNN-GRU (encoder)&lt;/td&gt;
      &lt;td&gt;0.9628888905048371&lt;/td&gt;
      &lt;td&gt;0.9414999961853028&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Bidirectional RNN-LSTM&lt;/td&gt;
      &lt;td&gt;0.9951481461524964&lt;/td&gt;
      &lt;td&gt;0.9171666741371155&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h5 id=&quot;some-resources&quot;&gt;Some resources:&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;How to implement Seq2Seq LSTM Model in Keras: https://towardsdatascience.com/how-to-implement-seq2seq-lstm-model-in-keras-shortcutnlp-6f355f3e5639&lt;/li&gt;
  &lt;li&gt;Difference Between Return Sequences and Return States for LSTMs in Keras: https://machinelearningmastery.com/return-sequences-and-return-states-for-lstms-in-keras/&lt;/li&gt;
  &lt;li&gt;Sequence Classification with LSTM Recurrent Neural Networks in Python with Keras: https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/&lt;/li&gt;
  &lt;li&gt;A ten-minute introduction to sequence-to-sequence learning in Keras: https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html&lt;/li&gt;
  &lt;li&gt;Understanding Tensorflow’s tensors shape: static and dynamic: https://pgaleone.eu/tensorflow/2018/07/28/understanding-tensorflow-tensors-shape-static-dynamic/&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Zizhun Guo</name></author><category term="Projects" /><summary type="html">Experiment</summary></entry><entry><title type="html">(5/8)Textual Models - Text Mining for Multiclass Classification based on Yelp User’s Reviews</title><link href="http://localhost:4001/jekyll/update/projects/2020/12/15/Text-Mining-Texual-Models.html" rel="alternate" type="text/html" title="(5/8)Textual Models - Text Mining for Multiclass Classification based on Yelp User’s Reviews" /><published>2020-12-15T13:50:04-05:00</published><updated>2020-12-15T13:50:04-05:00</updated><id>http://localhost:4001/jekyll/update/projects/2020/12/15/Text-Mining-Texual-Models</id><content type="html" xml:base="http://localhost:4001/jekyll/update/projects/2020/12/15/Text-Mining-Texual-Models.html">&lt;h3 id=&quot;textual-features&quot;&gt;Textual Features&lt;/h3&gt;
&lt;hr /&gt;

&lt;h3 id=&quot;1-tuning-parameters-for-w2v-model-and-logistic-regression-model&quot;&gt;1. Tuning Parameters for W2V model and Logistic Regression model&lt;/h3&gt;

&lt;p&gt;Since the tasks are classification related hence the carefully selected classifiers play important roles. Based on the embedded words vectors from the W2V model, where the VxN weights matrix contains all vocabulary vectors where it linearly spans in a fixed(smaller than vocabulary total length) number of dimensions space. Here it introduces two different classifiers for the tuning works.&lt;/p&gt;

&lt;h5 id=&quot;11-f1-score-comparison-under-different-w2v-models-and-sizes-lr-solvers-and-penalties&quot;&gt;1.1. F1 Score comparison under different w2v models and sizes, LR solvers and penalties&lt;/h5&gt;

&lt;p&gt;&lt;strong&gt;w2v models&lt;/strong&gt;: Continuous-bag-of-words (CBOW) and Skip-grams (SG)
&lt;strong&gt;w2v sizes&lt;/strong&gt;: The number of dimensions (N) of the N-dimensional space that gensim Word2Vec maps the words onto.
&lt;strong&gt;LR solvers&lt;/strong&gt;: The algorithms to optimize the loss function.
&lt;strong&gt;LR penalty&lt;/strong&gt;: To specify the norm used in the penalization (regularization).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;W2V Params options:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The tuning process try fitting the model in SG and CBOW, under each version model, it fits the models infeature numbers in 12 options. 2 * 12 = 24 W2V rounds fitting.
```py {.line-numbers}&lt;/p&gt;
&lt;h1 id=&quot;w2v-params-options&quot;&gt;W2V params options&lt;/h1&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;for sg in [0, 1]:
    for size in [10,20,30,40,50,100,150,200,250,300,400,500]:
        word2vec_model = Word2Vec(cutWords_list, sg = sg, size=size, iter=30, min_count=5,
                                    workers=multiprocessing.cpu_count()) ``` The tuning process would try l1 norm and liblinear first, and switch to l2 norm with 4 other penalties: liblinear, newton-cg, lbfgs and sag. (1 + 4) = 5 model training and testing for each W2V round.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;LR params options:

{'penalty': ['l1'], 'solver': ['liblinear']},
{'penalty': ['l2'], 'solver': ['liblinear','newton-cg', 'lbfgs', 'sag']}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The newton-cg, lbfgs and sag optimization algorithms require loss function being able to calculate first and second continuous derivative, hence L1-norm (manhattan distance) should not employ them. However, liblinear works fine in both L1-norm and L2-norm. The LR works fine for multiclass classification, but only in One-vs-Rest(OvR) for liblinear, which works worse than many-va-many(MvM) strategy in theories.
In total, the overall task tuning times are 24 * 5 = 120 times.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4001/assets/2020-12-15-Text-Mining/images/textual_models/LR_sizes_f1_new.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;W2V model analysis:&lt;/strong&gt;
SG overall performs better than CBOW from the beginning to end, where it has around 3 percent differences of F1 score, which is considered to be high contrast since the average F1 increase in variant W2V sizes are relatively small. Based on the images, the W2V models in the first 6 sizes (particularly 10, 20, 30, 40, 50, 100), the increase rate of F1 is high, the trend shows the promising upwards direction almost get vertical, after size becoming 100, the upward trends mitigate and gets more flattened. This is because the model fits convergence in which more features would not hugely benefit the classification and rather to intensify the machine resources. 
The recommend params are SG and size between 200 to 400 whereas the W2V models has 3356 vocabulary and 6000 samples numbers.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;LR model analysis:&lt;/strong&gt;
As previously mentioned, the liblinear algorithm works fine for multiclass classification but only in OvR strategy, therefore when performing multiclass LR, the F1 is smaller than other algorithms. The curve proves it that either by using SG or CBOW, the lines in colors blue, orange, brown, and pink always are less performative than other lines of algorithms. The results given by the other three algorithms show the lines are overlapped with each other. This is because the F1 score is too close (in 0.01% - 0.001% granularity) therefore the Matplotlib could not show the difference (It can be solved by plotting the logarithmic version of F1 comparison). This means at least for this experiment cases, the algorithms newton-cg, lbfgs and sag work well.&lt;/p&gt;

&lt;h5 id=&quot;12-f1-score-comparison-under-different-w2v-iteration-time-lr-solvers-and-penalties&quot;&gt;1.2. F1 Score comparison under different w2v Iteration time, LR solvers, and penalties&lt;/h5&gt;
&lt;p&gt;The iteration times decide how much the W2V is well trained in rounds just by comprehend words’ meanings. The tuning process takes different values of iteration parameters to check how this affects the final performance.
```py {.line-numbers}&lt;/p&gt;
&lt;h1 id=&quot;w2v-params-options-1&quot;&gt;W2V params options&lt;/h1&gt;

&lt;p&gt;for sg in [0, 1]:
    for iters in [1,2,3,4,5,10,15,20,30,40,50]:
        word2vec_model = Word2Vec(cutWords_list, sg = sg, size=300,iter=iters, min_count=5, workers=multiprocessing.cpu_count())&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;**Attention**: The feature size is set to be 300, which comes from the previous test that 300 is considered to be a good candidate to produce high F1 in the end.

![](http://localhost:4001/assets/2020-12-15-Text-Mining/images/textual_models/LR_iter_f1_new.png)
**W2V model Iteration time analysis:**
Same as previous experiments illustrated, SG has better performance than CBOW in the case dealing with a small number of samples, hence the images tell in the overall perspective, SG always performs better. The curves are sigmoid-like that in the range of 1 to 10 iteration times, the trend is exponential whereas each more iteration times gives a huge performance increase. It however converges to once the iteration times gets to 20 above, which makes sense that the embedding model is tuned to be the most fitted to the current samples.

---
### 2. Tuning Parameters for SVC model

##### 2.1. F1 Score comparison under different w2v models and sizes, LR solvers and penalties
**RBF** kernel function is used for tuning the SVC classifier. It has two essential parameters that determine the final performance. The SVC costs usually much more time than other classifiers when training/testing, but will be quick for prediction on validation datasets.

**SVC C**: The regularization parameter. The strength of the regularization is inversely proportional to C. This is a relaxation coefficient to balance the relationship between the complex of support vectors and the mis-classification rate. 
**SVC gamma**: This is a hyper-parameter that is commonly set to be 1/# features. This parameter defines how much a single sample can affect the hyper-plane.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;SVC params options&lt;/p&gt;

&lt;p&gt;param_grid = [
{‘estimator__kernel’: [‘rbf’], “estimator__C”:[0.1, 1.0, 10], “estimator__gamma”:[1.0, 0.1, 0.01, 0.03]}
]&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;The tuning process will run 3 * 4 = 12 times for each param pair try.
![](http://localhost:4001/assets/2020-12-15-Text-Mining/images/textual_models/SVC_f1_C.png)
The images show that as the values of C gets bigger, the F1 increases. The trends apply to all combinations of gamma values. This is because as C gets larger, the loss function becomes more tolerant to those points in further space thus treat them as support vectors. However, it makes the hyper-planes become more complex which may cause the model to suffers overfitting issues. As C gets small, fewer samples would become the support vectors thus the model gets simpler.

![](http://localhost:4001/assets/2020-12-15-Text-Mining/images/textual_models/SVC_f1_gamma.png)
The trends for F1 scores under different gamma values look similar to what it is showed from VS C's. When gamma is small, the single sample has less impact on the hyper-plane therefore be less possible to be selected as support vectors. By the way, it is interesting to see the gamma differences particularly impacts more on the small C's model. This phenomenon tells that as C gets large, the influence of gamma becomes least.


---
##### 2.2. Comparison between LR and SVC
W2V &amp;amp; LR:
- size = 400
- iter = 30
- sg = SG
- penalty = 'l2'
- solver = 'sag'

F1: **0.82721686**

W2V &amp;amp; SVC:
- size = 400
- iter = 30
- sg = SG
- C = 1.0
- gamma = 1.0

F1: **0.83151219**

It is hard to say Using SVC is better than LR, since the difference of F1 scores is not significant, only 0.43% around. In the perspective of fitting time for their two, SVC spent 4 times of time than what is costed by LR. Each classifier employs multiclass classification strategies to deal with the experiment case.



### 3. Tuning Parameters for GloVe model and Logistic Regression model

Since the tasks are classification related hence the carefully selected classifiers play important roles. Based on the embedded words vectors from the GloVe model, where the VxN weights matrix contains all vocabulary vectors where it linearly spans in a fixed(smaller than vocabulary total length) number of dimensions space. Here it introduces two different classifiers for the tuning works.

##### 3.1. F1 Score comparison under different w2v/GloVe models and sizes, LR solvers and penalties

**w2v models**: Continuous-bag-of-words (CBOW) and Skip-grams (SG)
**w2v sizes**: The number of dimensions (N) of the N-dimensional space that gensim Word2Vec maps the words onto.
**LR solvers**: The algorithms to optimize the loss function.
**LR penalty**: To specify the norm used in the penalization (regularization).

**W2V Params options:**

The tuning process try fitting the model in SG and CBOW, under each version model, it fits the models infeature numbers in 12 options. 2 * 12 = 24 W2V rounds fitting.
```py {.line-numbers}
# W2V params options
    for sg in [0, 1]:
        for size in [10,20,30,40,50,100,150,200,250,300,400]:
            word2vec_model = Word2Vec(cutWords_list, sg = sg, size=size, iter=30, min_count=5,
                                        workers=multiprocessing.cpu_count())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The tuning process would try l1 norm and liblinear first, and switch to l2 norm with 4 other penalties:
liblinear, newton-cg, lbfgs and sag. (1 + 4) = 5 model training and testing for each W2V round.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;LR params options:

{'penalty': ['l1'], 'solver': ['liblinear']},
{'penalty': ['l2'], 'solver': ['liblinear','newton-cg', 'lbfgs', 'sag']}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The newton-cg, lbfgs and sag optimization algorithms require loss function being able to calculate first and second continuous derivative, hence L1-norm (manhattan distance) should not employ them. However, liblinear works fine in both L1-norm and L2-norm. The LR works fine for multiclass classification, but only in One-vs-Rest(OvR) for liblinear, which works worse than many-va-many(MvM) strategy in theories.
In total, the overall task tuning times are 24 * 5 = 120 times.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4001/assets/2020-12-15-Text-Mining/images/textual_models/LR_sizes_f1_new.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;GloVe model size analysis:&lt;/strong&gt;
The size of the word vectors shows a general similar upwards trend comparing with SG and CBOW. However, the f1 scores soar at the very beginning when the word vectors size is below 100, the increasing rate is higher than SG and CBOW, but since the starting f1 score is lower than both, the GloVe model ends up being in the middle performance before CBOW eventually exceeds it. The overall performance shows that SG is still out-performed than CBOW and GloVe, whereas the differences between CBOW and GloVe are not significant.&lt;/p&gt;

&lt;h5 id=&quot;32-f1-score-comparison-under-different-w2vglove-iteration-time&quot;&gt;3.2. F1 Score comparison under different w2v/GloVe Iteration time&lt;/h5&gt;
&lt;p&gt;The iteration times decide how much the W2V/GloVe is well trained in rounds just by comprehend words’ meanings. The tuning process takes different values of iteration parameters to check how this affects the final performance.
```py {.line-numbers}&lt;/p&gt;
&lt;h1 id=&quot;w2v-params-options-2&quot;&gt;W2V params options&lt;/h1&gt;

&lt;p&gt;for sg in [0, 1]:
    for iters in [1,2,3,4,5,10,15,20,30,40,50]:
        word2vec_model = Word2Vec(cutWords_list, sg = sg, size=300,iter=iters, min_count=5, workers=multiprocessing.cpu_count())&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;**Attention**: The feature size is set to be 300, which comes from the previous test that 300 is considered to be a good candidate to produce high F1 in the end.

![](http://localhost:4001/assets/2020-12-15-Text-Mining/images/textual_models/LR_iters_f1_new.png)
**GloVe model Iteration time analysis:**
Same as previous experiments illustrated, SG has better performance than CBOW and GloVe in all cases. GloVe also plays in the middle role between SG and CBOW, but in this case (comparing iteration times), GloVe has almost the same score increasing rate. Interesting thing is, when the iteration is low, the GloVe performs close to SG, whereas when iteration time gets larger (greater or equal to 20), the GloVe is beaten by SG and close to the CBOW. In the end, CBOW and GloVe have emerged into similar performances.

##### 3.3. F1 Score comparison under different w2v/GloVe Window size
```py
    windows = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]
        for window in windows:
            ...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4001/assets/2020-12-15-Text-Mining/images/textual_models/LR_windows_f1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;GloVe model Window size analysis:&lt;/strong&gt;
The window size also decides all three models’ performances. As can be seen from the figure, the very model that has most influenced by the window size is GloVe, since GloVe is highly dependent on the co-occurrence matrix statistically extracted from the corpora. If the size of the window is small, the loss function would suffer the heavier than SG and CBOW. The best window size in our case is around 17, which means there would be 17 up ahead and down below (in total 34) neighboring words would be counted when producing the co-occurrence matrix.&lt;/p&gt;

&lt;hr /&gt;
&lt;h3 id=&quot;4-comparison-w2vglove-results-under-different-classifiers&quot;&gt;4. Comparison W2V/GloVe Results under different classifiers&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4001/assets/2020-12-15-Text-Mining/images/textual_models/F1_vs_models_clrs.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We employed five classifiers based on different classification methodologies and best-tuned parameters to conduct the experiments on the exact same features and target values. The results showed the MNB produced the least results and LR out-performed among all. The highest score that gets from the records is 0.82806571 from SVM-SG, and the lowest score came from the same classifiers which are 0.69019009 from SVM-CBOW. This shows the high contrast of performances using SVM model. The highest average f1 score came from LR, whereas LR-GloVe, LR-SG, and LR-CBOW are all exceeded 0.80. The other two classifiers performed close - the scores range from 0.70 to 0.75. When it comes to the comparison among the textual models, SG wined over all others which proved it to be the best-performed choice of textual model. CBOW should be the second place but in some cases (SVM or LR), GloVe is better. In terms of the classifiers’ ability of model tolerance, RF produces the most averaged results and LR is similar.&lt;/p&gt;

&lt;h3 id=&quot;appendix&quot;&gt;Appendix&lt;/h3&gt;

&lt;h5 id=&quot;a1-tuning-technique-scikit-learn-gridsearch&quot;&gt;A1. Tuning technique: Scikit-learn GridSearch&lt;/h5&gt;
&lt;p&gt;GaridSearchCV is a convenient tool for the usage of tuning the parameters under different models. The way to use it shows below:
```py {.line-numbers}
from sklearn.model_selection import GridSearchCV&lt;/p&gt;

&lt;p&gt;param_grid = [
{‘n_estimators’: [3, 10, 30], ‘max_features’: [2, 4, 6, 8]},
{‘bootstrap’: [False], ‘n_estimators’: [3, 10], ‘max_features’: [2, 3, 4]},
]&lt;/p&gt;

&lt;p&gt;forest_reg = RandomForestRegressor()
grid_search = GridSearchCV(forest_reg, param_grid, cv=5,
                          scoring=’neg_mean_squared_error’)&lt;/p&gt;

&lt;p&gt;grid_search.fit(housing_prepared, housing_labels)&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;The parameters grid contains a different set of parameter options. Every dictionary represents one possible set of parameters, it is different than the item pairs inside of it since each inside pairs can be using to perform one type of tuning process while the outer dictionary can be used to set for separate goals. (The parameters for different classifiers are designed differently sometimes)

For different inner classifers like (where classifiers are wrapped by an outer package):
```py
    param_grid = [
        {'estimator__kernel': ['rbf'], &quot;estimator__C&quot;:[10], &quot;estimator__gamma&quot;:[1.0]}
        ]
    clf = OneVsOneClassifier(SVC())
    grid_search = GridSearchCV(clf, param_grid, cv=10,
                          scoring=scoring, return_train_score = True, refit=False, iid = True)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The parameter names have to be in form of inner members. 
The GridSearchCV allows performing K-fold Cross Validations.&lt;/p&gt;

&lt;h5 id=&quot;a2-w2v&quot;&gt;A2. W2V&lt;/h5&gt;

&lt;p&gt;W2V is a word embedding technique for natural language processing(NLP). It uses a shallow neural network with one hidden layer to learn a large corpus of text. After tokenized the documents, it transformed the one-hot encoding words into the embedded words vectors through the hidden layer weight matrix. The output vector for this neural network ends up being the probability distribution for all words vocabulary.&lt;/p&gt;

&lt;p&gt;This technique takes into account the words pair through the window sampling, whereas the neighboring words would be taken as input and output for the neural network hence to tuning the weights matrix through model training. There are two types of neural network structures: CBOW and Skip-gram. Both models assume the neighboring words are closely relevant. CBOW is motivated that the words are decided by its neighboring words. The Skip-gram is different in that each word determines the neighboring ones.&lt;/p&gt;

&lt;p&gt;In this report, given the corpus of Yelp reviews are commonly what customers make on the restaurant services, hence the words are natual committed articles in which the words are composed in specific orders in human habits that contain semantics through nearby words pairs. It would be good to implement the W2V model in this case. The package for implementing the model is by Genism word2vecoter.&lt;/p&gt;

&lt;h6 id=&quot;a21-genism-w2v-implementation&quot;&gt;A2.1 Genism W2V Implementation&lt;/h6&gt;

&lt;p&gt;To implement the model, the first step is to convert the corpus(a list of documents where each document is a complete sentence in a string type) into a list of lists, where each inner list contains the tokenized vocabularies extracted from each document:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[
    ['love', 'deagan'],
    ['walk', 'right', 'assum', 'crowd'],
    ...
    ['check', 'event', 'attend']
]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This list is called cutwords list. The Genism W2V model would take in this list and convert and train it into the word vectors.&lt;/p&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;word2vec_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Word2Vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cutWords_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;300&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min_count&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;workers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multiprocessing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cpu_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h6 id=&quot;a22-prints-the-most-similar-words&quot;&gt;A2.2 Prints the most similar words&lt;/h6&gt;
&lt;p&gt;The W2V model can be used to list most similar words with given word. The ouputs are sorted by the Coscine Similarity:
```py {.line-numbers}
print(word2vec_model.wv.most_similar(‘good’))&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;[(‘decent’, 0.7268179655075073),
(‘moder’, 0.7154113054275513),
(‘ordinari’, 0.7079516053199768),
(‘darn’, 0.707633376121521),
(‘alright’, 0.7061334848403931),
(‘drawback’, 0.7018848657608032),
(‘great’, 0.6995223164558411),
(‘prob’, 0.6944646835327148), 
(‘prici’, 0.6898257732391357), 
(‘rival’, 0.6890593767166138)]&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;As reulsts showed, given input word 'good', the most output words are adjectives as 'good' is. ('decent', 'moderate', 'ordinary', 'alright', 'great', 'pricy')

###### A2.3 Prints the similarity between two words
The model can also be used to produced the similarity between two words.
```py {.line-numbers}
print(word2vec_model.similarity('waitress', 'waiter'))
print(word2vec_model.similarity('fork', 'sour'))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;0.76473266
0.60534066
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The word ‘Waitress’ is much closely related to ‘waiter’ than the words pair between ‘fork’ and ‘sour’.&lt;/p&gt;

&lt;hr /&gt;
&lt;h5 id=&quot;a3-feature-engineering-x-and-ordinal-label-encoding-y&quot;&gt;A3 Feature Engineering (X) and Ordinal Label encoding (y)&lt;/h5&gt;
&lt;p&gt;Just by getting the trained W2V model does not satisfy the needs. The Train dataset has to be converted from the original strings of sentences into the word vectors.&lt;/p&gt;
&lt;h6 id=&quot;a31-represent-each-document-as-a-word-vector&quot;&gt;A3.1 Represent each document as a word vector&lt;/h6&gt;
&lt;p&gt;For every document, the word vector for each word can be obtained from the model weights matrix. The document can be represented by the mean of all word vectors.
```py {.line-numbers}
def get_contentVector(cutWords, word2vec_model):
    ‘’’
        Getting the mean word vector for each document
        @cutWords: document cut words list
    ‘’’
    vector_list = [word2vec_model.wv[k] for k in cutWords if k in word2vec_model]
    contentVector = np.array(vector_list).mean(axis=0)
    return contentVector&lt;/p&gt;

&lt;p&gt;cutWords_list = [x.split(“ “) for x in X_original]
X = [get_contentVector(cutWords, word2vec_model) for cutWords in cutWords_list]&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;###### A3.2 Multiclass label encoding
Since it has 3 classes(American(New), Sushi Bars and Fast food), it needs to convert the categorical target values into ordinal values. The way to implement it is by using Scikit-learn LabelEncoder.
```py {.line-numbers}
y = labelEncoder.fit_transform(df['category'])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Zizhun Guo</name></author><category term="Projects" /><summary type="html">Textual Features</summary></entry><entry><title type="html">(4/8)Regular Features - Text Mining for Multiclass Classification based on Yelp User’s Reviews</title><link href="http://localhost:4001/jekyll/update/projects/2020/12/15/Text-Mining-Regular_Features.html" rel="alternate" type="text/html" title="(4/8)Regular Features - Text Mining for Multiclass Classification based on Yelp User’s Reviews" /><published>2020-12-15T13:50:03-05:00</published><updated>2020-12-15T13:50:03-05:00</updated><id>http://localhost:4001/jekyll/update/projects/2020/12/15/Text-Mining-Regular_Features</id><content type="html" xml:base="http://localhost:4001/jekyll/update/projects/2020/12/15/Text-Mining-Regular_Features.html">&lt;h2 id=&quot;regular-features&quot;&gt;Regular Features&lt;/h2&gt;

&lt;h3 id=&quot;python-files&quot;&gt;Python Files&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;hours.py&lt;/strong&gt;: This files contains the python code to extract feature ‘hours’.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;0-dataset-preview&quot;&gt;0. Dataset preview&lt;/h3&gt;
&lt;p&gt;X_regular:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;                                               hours 
0  {'Tuesday': '11:0-22:0', 'Wednesday': '11:0-22... 
1  {'Monday': '9:0-0:0', 'Tuesday': '9:0-0:0', 'W...  
2  {'Monday': '10:30-21:0', 'Tuesday': '10:30-21:... 
3  {'Tuesday': '10:0-17:0', 'Wednesday': '10:0-17... 
4  {'Monday': '11:0-21:0', 'Tuesday': '11:0-21:0'...  
5  {'Monday': '11:0-20:0', 'Tuesday': '11:0-21:0'...  
6  {'Monday': '17:0-23:0', 'Tuesday': '17:0-23:0'... 
7  {'Monday': '0:0-0:0', 'Tuesday': '17:0-22:0', ... 
8  {'Monday': '7:0-22:0', 'Tuesday': '7:0-22:0', ...
9  {'Monday': '6:0-6:0', 'Tuesday': '6:0-6:0', 'W... 

n_samples: 6000
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;y:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[0 1 1 0 1 0 0 2 1 2]

n_targets: 6000
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;attention-the-part-1-results-are-conducted-under-a-different-experiement-the-goals-are-changed-therefore-the-results-cannot-be-compared-with-other-documents&quot;&gt;Attention: The part 1 results are conducted under a different experiement, the goals are changed. Therefore, the results cannot be compared with other documents.&lt;/h3&gt;
&lt;h3 id=&quot;1-feature-extraction&quot;&gt;1. Feature Extraction&lt;/h3&gt;
&lt;p&gt;We perform two steps operations to conduct Feature Extraction: Feature Creation and Feature Selection.&lt;/p&gt;
&lt;h5 id=&quot;11-feature-creation&quot;&gt;1.1 Feature Creation&lt;/h5&gt;

&lt;p&gt;The dataset we have looks like this:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;   Unnamed: 0                                              hours   categories             business_id
0           0  {'Monday': '10:0-3:0', 'Tuesday': '10:0-3:0', ...      Burgers  tLpkSwdtqqoXwU0JAGnApw
1           1  {'Monday': '0:0-0:0', 'Tuesday': '11:0-21:0', ...        Pizza  ZkzutF0P_u0C0yTulwaHkA
2           2  {'Monday': '11:0-21:0', 'Tuesday': '11:0-21:0'...        Pizza  0y6alZmSLnPzmG5_kP5Quw
3           3  {'Monday': '11:0-22:0', 'Tuesday': '11:0-22:0'...        Pizza  Yr_w9lakJrKMyEG_hI6zbA
4           4  {'Monday': '11:0-22:0', 'Tuesday': '11:0-22:0'...      Burgers  Yr_w9lakJrKMyEG_hI6zbA
5           5  {'Monday': '11:30-0:0', 'Tuesday': '11:30-0:0'...  Steakhouses  cicPsia8Wj-DNRkmLbD_xg
6           6  {'Monday': '11:0-20:0', 'Tuesday': '11:0-20:0'...        Pizza  YHWjW9GLcuNtnh_xdCSOeA
7           7  {'Monday': '6:0-21:0', 'Tuesday': '6:0-21:0', ...      Burgers  GDf1SI_SnW93_lJN__egrQ
8           8  {'Monday': '6:0-23:0', 'Tuesday': '6:0-23:0', ...      Burgers  CfwrsG76Wm4iLS22v_wAcg
9           9  {'Monday': '10:0-2:0', 'Tuesday': '10:0-2:0', ...      Burgers  grZ6FnfZoj1pQWElAQve3g
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;For non-textual features, in this case ‘hours’, we need to break it into numerical values to make it sense for the training/testing process.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    categories    m1    m2    t1    t2    w1    w2   th1   th2    f1    f2    s1    s2   su1   su2
0      Burgers  10.0  27.0  10.0  27.0  10.0  27.0  10.0  27.0  10.0  27.0  10.0  27.0  10.0  27.0
1        Pizza   0.0   0.0  11.0  21.0  11.0  21.0  11.0  21.0  11.0  22.0  11.0  22.0  11.0  20.0
2        Pizza  11.0  21.0  11.0  21.0  11.0  21.0  11.0  22.0  11.0  22.0  11.0  22.0  11.0  21.0
3        Pizza  11.0  22.0  11.0  22.0  11.0  22.0  11.0  22.0  11.0  22.0  11.0  22.0  11.0  22.0
4      Burgers  11.0  22.0  11.0  22.0  11.0  22.0  11.0  22.0  11.0  22.0  11.0  22.0  11.0  22.0
5  Steakhouses  11.3  24.0  11.3  24.0  11.3  24.0  11.3  24.0  11.3  25.0  16.0  25.0  16.0  23.0
6        Pizza  11.0  20.0  11.0  20.0  11.0  20.0  11.0  20.0  11.0  21.0  11.0  21.0  11.0  19.0
7      Burgers   6.0  21.0   6.0  21.0   6.0  21.0   6.0  21.0   6.0  22.0   6.0  22.0   6.0  21.0
8      Burgers   6.0  23.0   6.0  23.0   6.0  23.0   6.0  23.0   6.0  23.0   6.0  23.0   6.0  23.0
9      Burgers  10.0  26.0  10.0  26.0  10.0  26.0  10.0  26.0  10.0  26.0  10.0  26.0  10.0  26.0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As it is similarly processed from the last experiment, we transformed the json format hours into 14 independent features represents the opening and closing hours on weekdays for each restaurant. (Unit: hours)
&lt;strong&gt;We reasonably keep all features for now, since we assume even one independent time could be a significant feature that helps for the classification.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;To test our assumption, we pair opening hours and closing hours for each day to plot the scatter to check the distribution of the restaurants.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Not all restaurants open on all days within a week, we define these restaurants as &lt;strong&gt;outliers&lt;/strong&gt; when the days they are not open. To solve such N/A value issue, we replace the null values by &lt;strong&gt;negative values&lt;/strong&gt;, so that is how the restaurants in left-down corner come from.&lt;/li&gt;
  &lt;li&gt;We also add some ‘fudge factor’ on the distribution scatter since if we do not do that, points are &lt;strong&gt;overlapped with each other&lt;/strong&gt; which gets hard to tell the &lt;strong&gt;density&lt;/strong&gt; of distribution. The noise we add is Gaussian Distributed in the range of 0 to 1 inclusive (Unit: hour).&lt;/li&gt;
  &lt;li&gt;There are some restaurants open 24 hours 7 days a week, so they mark their opening hours and closing hours for that day as &lt;strong&gt;‘0:00’ - ‘0:00’&lt;/strong&gt;, this explains there is also a cluster of points that are around the origins of the coordinates. (e.g. &lt;a href=&quot;https://www.yelp.com/biz/east-ridge-diner-and-steakhouse-rochester&quot;&gt;Steakhouse: East Ridge Diner &amp;amp; Steakhouse&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4001/assets/2020-12-15-Text-Mining/images/hours/monday_scatter.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;http://localhost:4001/assets/2020-12-15-Text-Mining/images/hours/tuesday_scatter.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;http://localhost:4001/assets/2020-12-15-Text-Mining/images/hours/wednesday_scatter.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;http://localhost:4001/assets/2020-12-15-Text-Mining/images/hours/thursday_scatter.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;http://localhost:4001/assets/2020-12-15-Text-Mining/images/hours/friday_scatter.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;http://localhost:4001/assets/2020-12-15-Text-Mining/images/hours/saturday_scatter.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;http://localhost:4001/assets/2020-12-15-Text-Mining/images/hours/sunday_scatter.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;After &lt;strong&gt;visually observation&lt;/strong&gt;, we found for most restaurants, the closing hours are hard to tell the classes of different restaurants(mapped to y-coordinate), but the opening hours do, though there are many restaurants overlapped around 10 AM. One interesting phenomenon is it seems there are some Italian and Steakhouse restaurants that does not open on Monday and Sunday. However, we need to statistically test the relation later.&lt;/p&gt;

&lt;p&gt;Base on our observation, we created other attributes to explain the phenomenon:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;is24hoursAny(Binary feature that checks if the restaurant ever has one day that running 24 hours)&lt;/li&gt;
  &lt;li&gt;isMondayOpen(Binary feature that checks if the restaurant ever open on Monday)&lt;/li&gt;
  &lt;li&gt;isSundayOpen(Binary feature that checks if the restaurant ever open on Sunday)&lt;/li&gt;
  &lt;li&gt;weeklyBusinessHoursTotal(Total running hours of the entire week)&lt;/li&gt;
  &lt;li&gt;weeklyBusinessDaysTotal(Total running days of the entire week)&lt;/li&gt;
  &lt;li&gt;weeklyBusinessHoursAverage(Average hours running per day)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We label our 4 categories of restaurants as 1 from ‘Italian’ and ‘Steakhouse’, 0 from ‘Burgers’ and ‘Pizza’.
We calculate the Pearson Correlation Coefficient between each feature with targets values&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[(0.07407551311437341, 'm1'), 
(-0.11731578824302691, 'm2'), 
(0.4950215768112705, 't1'), 
(0.16077867219458727, 't2'), 
(0.5864094264798979, 'w1'), 
(0.21039753765592104, 'w2'), 
(0.6008755867323026, 'th1'), 
(0.22602446026919382, 'th2'), 
(0.6060301041747369, 'f1'), 
(0.2161271409426079, 'f2'), 
(0.6410376507620771, 's1'), 
(0.23164634299100906, 's2'), 
(0.08686741536964375, 'su1'), 
(-0.11269885908039662, 'su2'), 
(-0.13524901840982256, 'is24hoursAny'), 
(0.24307624944474643, 'isMondayOpen'), 
(0.23307751762726242, 'isSundayOpen'), 
(-0.5879066836052446, 'weeklyBusinessHoursTotal'),
(-0.27385921252217005, 'weeklyBusinessDaysTotal'), 
(-0.3730318736301774, 'weeklyBusinessHoursAverage')]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We found that the opening hours each day within a week have a strong connection with the classes. The ‘weeklyBusinessHoursTotal’ is also considered as a valuable feature.&lt;/p&gt;

&lt;p&gt;We also produce the cross-correlation matrix to check the redundancy for each feature pairs.
&lt;img src=&quot;http://localhost:4001/assets/2020-12-15-Text-Mining/images/hours/cc.png&quot; alt=&quot;&quot; /&gt;
It is interesting to find that ‘Friday closing hours’ is strongly relevant to ‘Saturday closing hours’(0.90). In actual scenes, we may assume Friday and Saturday are the real weekends for restaurant services. It is not surprising to find that the correlation coefficient from Monday and Sunday to any day else is weak. We may assume that these two days are normally the days that restaurants reducing their working hours or even shut down.&lt;/p&gt;

&lt;h3 id=&quot;appendix-food-relavant-keywords&quot;&gt;Appendix: Food relavant keywords&lt;/h3&gt;
&lt;h4 id=&quot;a1-list-most-common-words-using-countvecterizer&quot;&gt;A1. List most common words using CountVecterizer&lt;/h4&gt;
&lt;p&gt;To calculate the frequency for each word from the corpus, we need to employ the CountVectorizer from Scikit-learn to produce the matrix. We set the max feature numbers to 200 since the number of food-relevant keywords is much less than 200. IF the keywords numbers are expected to be large-sized, the feature numbers should be at least 10 times bigger than it. In this case, we expect 20 food-relevant keywords to extract.&lt;/p&gt;

&lt;p&gt;Each feature represent an word frequency. We need to sum up each feature’s frequency.
```py {.line-numbers}
from sklearn.feature_extraction.text import CountVectorizer&lt;/p&gt;

&lt;p&gt;cv=CountVectorizer(max_features = 200) 
word_count_vector=cv.fit_transform(df)
print(word_count_vector.todense())&lt;/p&gt;

&lt;p&gt;sum_words = word_count_vector.sum(axis=0) # numpy matrix (not recommend to use this class)
print(sum_words)&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;[[ 0  0  0 …  0  0  0]
 [ 0  0  0 …  0  0  0]
 [ 0  0  0 …  0  0  0]
 …
 [ 0 10  0 …  0  0  0]
 [ 0  0  0 …  0  0  0]
 [ 4 64  0 …  0  0  0]]&lt;/p&gt;

&lt;p&gt;[[ 4 98  2 …  2 10  2]]&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;We list out the vocabulary items in the countvectorizer which are stored in Python dictionary data structure and sorted the words in pairs in the tuple, where the first element represent the word itself and the second represent the word frequency from all corpus.
```py {.line-numbers}
words_freq = [(word, sum_words[0, idx]) for word, idx in cv.vocabulary_.items()]
words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)
print(words_freq)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In example below, ‘food’ was spotted 2610 times which makes it the most common word. Other words like ‘&lt;strong&gt;good&lt;/strong&gt;’, ‘&lt;strong&gt;service&lt;/strong&gt;’ and ‘&lt;strong&gt;order&lt;/strong&gt;’ showed up &lt;strong&gt;2126&lt;/strong&gt;, &lt;strong&gt;1962&lt;/strong&gt; and &lt;strong&gt;1874&lt;/strong&gt; times in all corpus.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[('food', 2610), ('good', 2126), ('service', 1962), ('order', 1874), ('place', 1654), ('come', 1524), ('great', 1506), ('like', 1384), ('time', 1322), ('restaurant', 1224), ('sushi', 1146), ('menu', 998), ('go', 896), ('breakfast', 798), ('price', 782), ('nice', 780), ('dish', 746), ('chicken', 700), ('mozen', 692), ('delicious', 690), ('fresh', 680), ('vegas', 676), ('best', 664), ('dinner', 636), ('brunch', 636), ('mandarin', 620), ('fry', 618), ('table', 618), ('roll', 608), ('love', 598), ('want', 578), ('taste', 576), ('look', 568), ('salad', 550), ('think', 546), ('amaze', 544), ('experience', 532), ('staff', 530), ('lunch', 522), ('wait', 512), ('meal', 508), ('definitely', 498), ('star', 494), ('little', 488), ('sauce', 478), ('better', 474), ('take', 472), ('hotel', 
470), ('drink', 468), ('pretty', 466), ('server', 464), ('excellent', 456), ('oriental', 454), ('burger', 444), ('friendly', 444), ('enjoy', 444), ('bento', 444), ('cheese', 428), ('buffet', 414), ('serve', 408), ('try', 408), ('ask', 402), ('flavor', 386), ('say', 384), ('recommend', 384), ('salmon', 384), ('know', 382), ('small', 380), ('soup', 380), ('quality', 368), ('expect', 364), ('review', 356), ('offer', 354), ('curry', 354), ('tell', 352), ('wasn', 350), ('give', 346), ('indian', 346), ('overall', 336), ('asian', 336), ('visit', 330), ('din', 326), ('need', 324), ('fish', 322), ('minutes', 316), ('leave', 316), ('disappoint', 310), ('dessert', 310), ('seat', 306), ('sure', 304), ('waitress', 304), ('tasty', 302), ('worth', 302), ('portion', 298), ('night', 298), ('room', 294), ('check', 288), ('eat', 284), ('stay', 282), ('people', 280), ('rice', 280), ('beef', 278), ('location', 278), ('right', 276), ('strip', 274), ('steak', 272), ('view', 270), ('fruit', 266), ('decide', 262), ('special', 260), ('feel', 256), ('start', 
256), ('crab', 256), ('cook', 254), ('chef', 254), ('egg', 254), ('work', 252), ('sashimi', 250), ('area', 248), ('high', 248), ('spicy', 246), ('perfect', 246), ('bread', 244), ('attentive', 242), ('different', 242), ('grill', 238), ('green', 232), ('japanese', 232), ('friends', 230), ('bring', 224), ('highly', 224), ('thai', 224), ('get', 222), ('awesome', 222), ('arrive', 222), ('walk', 222), ('husband', 220), ('atmosphere', 220), ('shrimp', 220), ('waiter', 220), ('entree', 220), ('long', 216), ('water', 216), ('bistro', 216), ('friend', 214), ('floor', 214), ('items', 212), ('favorite', 210), ('sunday', 210), ('super', 206), ('options', 206), ('sandwich', 204), ('sweet', 204), ('selection', 204), ('decent', 202), ('coffee', 200), ('bite', 198), ('thing', 196), ('probably', 192), ('away', 192), ('manager', 192),
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h4 id=&quot;a2-apply-nltk-wordnet-synset-to-extract-food-relevant-words&quot;&gt;A2. Apply NLTK wordnet synset to extract food-relevant words&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;WordNet&lt;/strong&gt; is the lexical database i.e. dictionary for the English language, specifically designed for natural language processing.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Synset&lt;/strong&gt; is a special kind of a simple interface that is present in NLTK to look up words in WordNet. Synset instances are the groupings of synonymous words that express the same concept. Some of the words have only one Synset and some have several.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hyponym:&lt;/strong&gt; Both come to picture as Synsets are organized in a structure similar to that of an inheritance tree. This tree can be traced all the way up to a root hypernym. Hypernyms provide a way to categorize and group words based on their similarity to each other.&lt;/p&gt;

&lt;p&gt;It is not enough to find the most common words in all ranges, extraction has to be narrowed down to food-relevant. In this case, we employ NLTK package wordnet synset to group all hyponyms that relates to ‘food’.&lt;/p&gt;

&lt;p&gt;```py {.line-numbers}
from nltk.corpus import wordnet as wn
nltk.download(‘wordnet’)&lt;/p&gt;

&lt;p&gt;food = wn.synset(‘food.n.02’)
print(type(food))
food_list = list(set([w for s in food.closure(lambda s:s.hyponyms()) for w in s.lemma_names()]))
food_list2 = [w.replace(‘_’, ‘ ‘) for s in food.closure(lambda s:s.hyponyms()) for w in s.lemma_names()]
print(food_list2)
print(len(words_freq))&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;'**food.n.02**' indicates the **2nd** deifnition of '**food**' as a **noun**.
Of all **hyponyms** of '**food**' as a **closure**, we extract their **lemma names** and group them as a list.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;[‘baked goods’, ‘breakfast food’, ‘butter’, ‘cheese’, ‘chocolate’, ‘coconut’, ‘coconut meat’, ‘convenience food’, ‘dika bread’, 
‘fish’, ‘fresh food’, ‘fresh foods’, ‘health food’, ‘junk food’, ‘leftovers’, ‘loaf’, ‘meat’, ‘pasta’, ‘alimentary paste’, 
‘produce’, ‘green goods’, ‘green groceries’, ‘garden truck’, ‘seafood’, ‘slop’, ‘yogurt’, ‘yoghurt’, ‘yoghourt’, ‘bread’, 
‘breadstuff’, ‘staff of life’, ‘cake’, ‘pastry’, ‘cereal’, ‘muesli’, ‘brown butter’, ‘beurre noisette’, ‘clarified butter’, 
…]&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;We looped over all features in food hyponyms to retain all food-relevant keywords and sorted all pairs in descending order.
```py {.line-numbers}
words_food_relevant = [(food, pair[1]) for pair in words_freq for food in food_list2 if pair[1] &amp;gt; 30 and pair[0] == food]
print(words_food_relevant)
print(len(words_food_relevant))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[('chicken', 700), ('mandarin', 620), ('roll', 608), ('cheese', 428), ('salmon', 384), ('fish', 322), ('beef', 278), 
('steak', 272), ('crab', 256), ('bread', 244), ('green', 232), ('shrimp', 220), ('bacon', 188), ('meat', 186), 
('tuna', 180), ('cake', 170), ('pork', 164), ('oyster', 160), ('mushroom', 140), ('toast', 140), ('tomato', 134), 
('scallop', 134), ('butter', 130), ('pasta', 122), ('seafood', 122), ('plate', 118), ('calamari', 116), ('pepper', 112), 
('naan', 112), ('chocolate', 96), ('roast', 96), ('waffle', 96), ('lettuce', 94), ('lamb', 88), ('noodle', 88), 
('game', 84), ('avocado', 82), ('potato', 76), ('spinach', 74), ('date', 72), ('bean', 70), ('mango', 70), ('stick', 66), ('turkey', 66), ('onion', 60), ('sausage', 60), ('yogurt', 60), ('veggie', 58), ('chili', 56), ('truffle', 56), 
('mustard', 50), ('side', 50), ('banana', 50), ('dumplings', 50), ('gnocchi', 50), ('apple', 48), ('prawn', 48), 
('lychee', 48), ('grouper', 48), ('vegetable', 46), ('joint', 46), ('cucumber', 46), ('chop', 44), ('orange', 42), 
('pumpkin', 42), ('duck', 42), ('polenta', 42), ('lemon', 38), ('wonton', 38), ('gorgonzola', 38), ('buffalo', 36), 
('muffin', 34), ('chipotle', 34), ('watermelon', 32)]
74
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4001/assets/2020-12-15-Text-Mining/images/regular_features/Figure_1.png&quot; alt=&quot;Image2&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;a3-the-top-k-food-keywords-discovery&quot;&gt;A3. The Top-K food keywords discovery&lt;/h4&gt;
&lt;p&gt;While the tasks are restaurants targetted classification, it is reasonable to try extracting the food-related keywords from the given text corpus to further decrease the feature dimensions. Previously, from the week4 experiment, it was successful to extract the food-relevant keywords by using NLTK wordnet dictionary, this time it is worth employing the same approach to experiment.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[
    ['shrimp'], ['chicken', 'chicken', 'round'], 
    [], 
    ['green', 'cheese', 'rib', 'chicken', 'strawberry', 'potato'], 
    ['roll'], 
    ['seafood', 'chicken', 'shrimp', 'shrimp', 'butter'], 
    ['tortilla', 'steak', 'steak', 'pepper'], 
    [], 
    [], 
    ['heart', 'heart'], 
    [], 
    ['chipotle', 'chipotle', 'veggie', 'green'], 
    ['pita'], 
    ['rib', 'salmon'],
    ...
    ]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The results show the transformed cut words list after the selection, where each member list represents a user review filtered by the vocabulary. The empty list can be commonly seen due to its original reviews contains no food relevant keywords. Due to the small size of the samples and imbalanced nature may hugely affect the performance, for those empty list we assign them zeros in the same length of W2V feature numbers.&lt;/p&gt;

&lt;p&gt;It is in nature just select more important keywords than extracting all words, so the performance however is worse than just extracting the regular reviews.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;W2V + LR params:

sg = 1
size=300
iter=30
{'penalty': ['l1'], 'solver': ['liblinear']},
{'penalty': ['l2'], 'solver': ['liblinear','newton-cg', 'lbfgs', 'sag']},
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;F1 scores:

l1 + liblinear: 0.541781294
l2 + liblinear: 0.542167673
l2 + newton-cg: 0.543132704
l2 + lbfgs: 0.543132704
l2 + sag: 0.543132704
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;resources&quot;&gt;Resources&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.kaggle.com/vksbhandary/exploring-yelp-reviews-dataset#Lets-find-relationship-between-users's-friends-and-review-patterns&quot;&gt;Kaggle: Exploring yelp reviews dataset&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/duoergun0729/nlp/blob/master/%E9%A2%84%E6%B5%8BYelp%E7%BE%8E%E9%A3%9F%E8%AF%84%E5%88%86.md&quot;&gt;Baidu: Yelp 情感分析&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://medium.com/@cristhianboujon/how-to-list-the-most-common-words-from-text-corpus-using-scikit-learn-dad4d0cab41d&quot;&gt;Medium: How to list the most common words from text corpus using Scikit-Learn?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://stackoverflow.com/questions/19626737/where-can-i-find-a-text-list-or-library-that-contains-a-list-of-common-foods&quot;&gt;StackOverflow: NLTK food corpus extraction&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Zizhun Guo</name></author><category term="Projects" /><summary type="html">Regular Features</summary></entry><entry><title type="html">(3/8)Preprocessing - Text Mining for Multiclass Classification based on Yelp User’s Reviews</title><link href="http://localhost:4001/jekyll/update/projects/2020/12/15/Text-Mining-Dataset_Preprocessing.html" rel="alternate" type="text/html" title="(3/8)Preprocessing - Text Mining for Multiclass Classification based on Yelp User’s Reviews" /><published>2020-12-15T13:50:02-05:00</published><updated>2020-12-15T13:50:02-05:00</updated><id>http://localhost:4001/jekyll/update/projects/2020/12/15/Text-Mining-Dataset_Preprocessing</id><content type="html" xml:base="http://localhost:4001/jekyll/update/projects/2020/12/15/Text-Mining-Dataset_Preprocessing.html">&lt;h3 id=&quot;preprocessing&quot;&gt;Preprocessing&lt;/h3&gt;
&lt;hr /&gt;
&lt;h3 id=&quot;python-files&quot;&gt;Python Files&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;stem_lemmatize.py&lt;/strong&gt;: This files contains the python code for tokenizing the review texts.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;dataset-after-stemmed&quot;&gt;Dataset after stemmed&lt;/h3&gt;
&lt;p&gt;X:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;0    love deagan atmospher cozi festiv shrimp taco ...
1    happi final can near casa grip drive pack like...
2    definit favorit fast food shop ingredi tast te...
3    twice nice lay tri weekend southern menu delic...
4    husband tri today amaz glad differ normal plea...
5    husband week year love seafood unfortun regret...
6    previous person post say restaur come vega mor...
7    choic default year dinner year choos reserv in...
8    employe friend hard work store clean love subw...
9    actual favorit hotel casino thing chang good c...

n_samples: 6000
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;X_stemmed:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;0    love deagan atmospher cozi festiv shrimp taco ...
1    happi final can near casa grip drive pack like...
2    definit favorit fast food shop ingredi tast te...
3    twice nice lay tri weekend southern menu delic...
4    husband tri today amaz glad differ normal plea...
5    husband week year love seafood unfortun regret...
6    previous person post say restaur come vega mor...
7    choic default year dinner year choos reserv in...
8    employe friend hard work store clean love subw...
9    actual favorit hotel casino thing chang good c...

n_samples: 6000
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;X_lemmatized: Since the content is from previous report hence Ignored.&lt;/p&gt;</content><author><name>Zizhun Guo</name></author><category term="Projects" /><summary type="html">Preprocessing Python Files stem_lemmatize.py: This files contains the python code for tokenizing the review texts.</summary></entry><entry><title type="html">(2/8)Dataset - Text Mining for Multiclass Classification based on Yelp User’s Reviews</title><link href="http://localhost:4001/jekyll/update/projects/2020/12/15/Text-Mining-Dataset.html" rel="alternate" type="text/html" title="(2/8)Dataset - Text Mining for Multiclass Classification based on Yelp User’s Reviews" /><published>2020-12-15T13:50:01-05:00</published><updated>2020-12-15T13:50:01-05:00</updated><id>http://localhost:4001/jekyll/update/projects/2020/12/15/Text-Mining-Dataset</id><content type="html" xml:base="http://localhost:4001/jekyll/update/projects/2020/12/15/Text-Mining-Dataset.html">&lt;h3 id=&quot;dataset&quot;&gt;Dataset&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;The dataset that we used was downloaded from Yelp. The original dataset has been firstly used for Yelp Dataset Challenge and is kept updating throughout the years. It contains information about reviews, business, users, and business check-ins. The main two datasets we use is business and reviews. We specially focus on &lt;strong&gt;6000&lt;/strong&gt; businesses evenly divided in &lt;strong&gt;3 categories&lt;/strong&gt; with their whole reviews concatenating together that the documents being features. The vocabulary size is around 180,000 which makes our documents source complex and rich in information enough to represent each business. The type of business we select is the restaurant specifically are marked in Sushi Bars, American New, and Fast Food. We believe it is firstly rich in information of the reviews due the Yelp Dataset are mainly focus on Restaurant service collection, and these three categories are not exactly similar whether in the business model or food service it provides.&lt;/p&gt;

&lt;p&gt;For each document, we only use 6000 characters (white space inclusive) for training due to the memory limitation while conduct deep learning training hence maintains the same dataset to use for the fair models’ comparison. We conduct 10-fold cross-validation, and we assume each review for each restaurant extracted from JSON dataset file is randomly ordered, but we have ranked the restaurant based on the number of reviews they have so that when conduct concatenation, it guarantees the most reviewed restaurants to be selected as the source restaurants.&lt;/p&gt;

&lt;h3 id=&quot;python-files&quot;&gt;Python Files&lt;/h3&gt;
&lt;p&gt;This directory contains the actual dataset used for the experiments.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;IS_new.csv&lt;/strong&gt; contains 4 columns(business_id, text, category, hours)  of 6000 balanced records (samples)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;IS.csv&lt;/strong&gt; contains 4 columns(business_id, text, category, hours)  of 6000 balanced records (samples). The difference is the reviews in text feature is stemmed, whereas in &lt;strong&gt;IS_new.csv&lt;/strong&gt; the reviews are lematized&lt;/li&gt;
  &lt;li&gt;PS: the original dataset can be download from &lt;a href=&quot;https://www.yelp.com/dataset&quot;&gt;Yelp Dataset&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;1-dataset-statistics&quot;&gt;1. Dataset Statistics&lt;/h3&gt;
&lt;p&gt;We use &lt;strong&gt;Yelp Dataset Business(Business)&lt;/strong&gt; and &lt;strong&gt;Yelp Dataset Reviews(Reviews)&lt;/strong&gt; to get training and testing samples. The main dataset to use is &lt;strong&gt;Reviews&lt;/strong&gt;. The &lt;strong&gt;Business&lt;/strong&gt; is helpful for tables joining to ensure the data balancing nature. Therefore, each sample attaches one review text. The samples from &lt;strong&gt;Reviews&lt;/strong&gt; nevertheless need to be sampled from unique &lt;strong&gt;Business&lt;/strong&gt; as the goal is to predict the category of the restaurants, so including more restaurants would be reasonable. &lt;a href=&quot;https://www.yelp.com/dataset/documentation/main&quot;&gt;Link: Yelp Dataset Schema&lt;/a&gt;&lt;/p&gt;

&lt;h5 id=&quot;11-select-balanced-data&quot;&gt;1.1 Select balanced data&lt;/h5&gt;
&lt;p&gt;Plotting histogram on both &lt;strong&gt;Business&lt;/strong&gt; and &lt;strong&gt;Reviews&lt;/strong&gt; help to identify the numbers of restaurants distribution.
&lt;img src=&quot;http://localhost:4001/assets/2020-12-15-Text-Mining/images/dataset/Restaurants_Cat_Hist.png&quot; alt=&quot;&quot; /&gt;
As the &lt;strong&gt;Business Histogram&lt;/strong&gt; image shows, if we include unique restaurants to filter the &lt;strong&gt;Reviews&lt;/strong&gt;, at most we can select &lt;strong&gt;2363&lt;/strong&gt; restaurants for each of three categories(‘Fast Food’, ‘American (New)’, ‘Sushi Bars’) since we want the samples to be balanced. The histogram also shows there exist restaurants that have both categories marked, but these samples’ number is too small to consider.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4001/assets/2020-12-15-Text-Mining/images/dataset/Restaurants_Cat_Reviews_Hist.png&quot; alt=&quot;&quot; /&gt;
We can also observe from the &lt;strong&gt;Reviews&lt;/strong&gt; histogram image, the number of samples is much overwhelmed than the &lt;strong&gt;Business&lt;/strong&gt; (one restaurant can have multiple reviews), so if we do not limit our restaurant’s uniqueness condition, we could have samples as large as 268026. In our case, we include &lt;strong&gt;2000&lt;/strong&gt; unique restaurants from each category to pre-process, of which the scalability is easy to handle. (In total &lt;strong&gt;6000&lt;/strong&gt; samples)&lt;/p&gt;

&lt;h3 id=&quot;2-sampling-steps&quot;&gt;2. Sampling steps&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;Select restaurants from only categories of ‘American (New)’, ‘Sushi Bars’ and ‘Fast Food’&lt;/li&gt;
  &lt;li&gt;Based on their reviews number, rank the restaurants in descending order (Group by and aggregation, Join two tables)&lt;/li&gt;
  &lt;li&gt;Select top 2000 restaurants for each category of restaurant as samples&lt;/li&gt;
  &lt;li&gt;Apply preprocessing on the samples.
Samples Update Conclusion (how it affects the experiment results):
•	Ranking proves to be a good way to ensure the utilized restaurants containing more information than just do randomly selection. Comparing to the dataset used from previous experiments, the median number of reviews counts for each restaurant to concatenate is between 100 to 200, the maximum reviews counts is 6000, the minimal is 3. This suggests the length for each review are at least hundreds of times over the previous method. This would yield a huge change on the final results.
•	With reviews scales enlarged, the sequence length increased. Unfortunately, because of the limitation on RAM size, for 10 GB available RAM can managed at least 12,800 tokens per sequence. However, the time spent on training would be linearly grew according to the tests, for a Nvidia GTX 1060 6GB video card with computing ability of 6.1, the training duration would be up to 15 hours for tuning Filter Region Size experiment. The benefits given a tiny improve less than 1 percent on validation accuracy. Therefore, for saving more time to conduct more tuning experiments, using 1000 tokens for padding the sequence length (where most reviews fully taken over the entire sequence without any zeros to pad the margin hence sequence matrix are dense) would expect to have decent output results.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;3-samples&quot;&gt;3. Samples&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;                                               hours                           text        category
0  {'Tuesday': '11:0-22:0', 'Wednesday': '11:0-22...      I love Deagan's. I do. I...  American (New)
1  {'Monday': '9:0-0:0', 'Tuesday': '9:0-0:0', 'W...      Oh happy day, finally ha...       Fast Food
2  {'Monday': '10:30-21:0', 'Tuesday': '10:30-21:...      This is definitely my fa...       Fast Food
3  {'Tuesday': '10:0-17:0', 'Wednesday': '10:0-17...      I have been here twice. ...  American (New)
4  {'Monday': '11:0-21:0', 'Tuesday': '11:0-21:0'...      Everything that my husba...       Fast Food
5  {'Monday': '11:0-20:0', 'Tuesday': '11:0-21:0'...      My husband and I go ther...  American (New)
6  {'Monday': '17:0-23:0', 'Tuesday': '17:0-23:0'...      As the previous person p...  American (New)
7  {'Monday': '0:0-0:0', 'Tuesday': '17:0-22:0', ...      This was our choice, by ...      Sushi Bars
8  {'Monday': '7:0-22:0', 'Tuesday': '7:0-22:0', ...      The employees are so fri...       Fast Food
9  {'Monday': '6:0-6:0', 'Tuesday': '6:0-6:0', 'W...      This actually used to be...      Sushi Bars

RangeIndex: 6000 entries, 0 to 5999
Data columns (total 3 columns):
 #   Column    Non-Null Count  Dtype
---  ------    --------------  -----
 0   hours     6000 non-null   object
 1   text      6000 non-null   object
 2   category  6000 non-null   object
dtypes: float64(1), object(3)

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;4-labels&quot;&gt;4. Labels&lt;/h3&gt;
&lt;p&gt;As the original labels are categorical labels: &lt;strong&gt;Sushi Bars&lt;/strong&gt;, &lt;strong&gt;American New&lt;/strong&gt;, and &lt;strong&gt;Fast Food&lt;/strong&gt;. It has to transform the categorical labels into numerical labels for the models to learn. We have transformed two types of labels (multiclass vs multilabel) for our learning models to output.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Category before re-label&lt;/th&gt;
      &lt;th&gt;‘Fast Food’&lt;/th&gt;
      &lt;th&gt;‘American (New)’&lt;/th&gt;
      &lt;th&gt;‘Sushi Bars’&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Category after re-label&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;index&lt;/th&gt;
      &lt;th&gt;category&lt;/th&gt;
      &lt;th&gt;Multiclass&lt;/th&gt;
      &lt;th&gt;Multilabel(One-hot Encoded)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;Sushi Bars&lt;/td&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;1	0	0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;Fast Food&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0	0	1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;Fast Food&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0	0	1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;American (New)&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0	1	0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;Fast Food&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0	0	1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;</content><author><name>Zizhun Guo</name></author><category term="Projects" /><summary type="html">Dataset The dataset that we used was downloaded from Yelp. The original dataset has been firstly used for Yelp Dataset Challenge and is kept updating throughout the years. It contains information about reviews, business, users, and business check-ins. The main two datasets we use is business and reviews. We specially focus on 6000 businesses evenly divided in 3 categories with their whole reviews concatenating together that the documents being features. The vocabulary size is around 180,000 which makes our documents source complex and rich in information enough to represent each business. The type of business we select is the restaurant specifically are marked in Sushi Bars, American New, and Fast Food. We believe it is firstly rich in information of the reviews due the Yelp Dataset are mainly focus on Restaurant service collection, and these three categories are not exactly similar whether in the business model or food service it provides.</summary></entry></feed>